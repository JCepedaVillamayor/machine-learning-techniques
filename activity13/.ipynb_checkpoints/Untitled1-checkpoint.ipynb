{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "import sys\n",
    "from database.models import get_db_session, AccidentDBScan, WorkZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtain workzones KNN\n",
    "session2007 = get_db_session('sqlite:///../incidencesAux.db')\n",
    "works = session2007.query(WorkZone.num_cluster).all()\n",
    "works_cluster = [i[0] for i in works]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "# Obtain KNN of accidents\n",
    "session2006 = get_db_session('sqlite:///../incidences.db')\n",
    "K = 2\n",
    "accidents = session2006.query(Incidencia).filter(Incidencia.tipo == 'Accidente').all()\n",
    "db_accidents = session2006.query(AccidentDBScan.longitud, \n",
    "                          AccidentDBScan.latitud,\n",
    "                          AccidentDBScan.num_cluster).all()\n",
    "accident_set = [x[:2] for x in db_accidents]\n",
    "zones = [x[2] for x in db_accidents]\n",
    "lat_and_lon_works = [(inc.longitud, inc.latitud) for inc in accidents]\n",
    "clf = neighbors.KNeighborsClassifier(K, weights='distance')\n",
    "clf.fit(accident_set, zones)\n",
    "accidents_cluster = clf.predict(lat_and_lon_works)\n",
    "print(len(set(accidents_cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "#Obtain the knn zones without roadworks\n",
    "no_coincidence = [i for i in accidents_cluster if i not in works_cluster]\n",
    "print(len(set(no_coincidence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Vuelco', 'Tijera camión', 'Alcance', 'Atropello', 'Salida'}\n",
      "[77, 25, 299, 12, 119]\n"
     ]
    }
   ],
   "source": [
    "#Obtain the accident type in the clusters without roadworks\n",
    "types_y = []\n",
    "for index, accident in enumerate(accidents):\n",
    "    if accidents_cluster[index] in set(no_coincidence):\n",
    "        types_y.append(accident.causa)\n",
    "        \n",
    "print(set(types_y))\n",
    "cause_y = [i for i in set(types_y)]\n",
    "cause_ammount_y = [0]*len(cause_y)\n",
    "\n",
    "for acc in types_y:\n",
    "    cause_ammount_y[cause_y.index(acc)] = cause_ammount_y[cause_y.index(acc)] + 1\n",
    "    \n",
    "print(cause_ammount_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Vuelco', 'Tijera camión', 'Alcance', 'Atropello', 'Salida'}\n",
      "[614, 50, 4925, 74, 1744]\n"
     ]
    }
   ],
   "source": [
    "#Obtain the accident type in the clusters with roadworks\n",
    "types_n = []\n",
    "for index, accident in enumerate(accidents):\n",
    "    if accidents_cluster[index] not in set(no_coincidence):\n",
    "        types_n.append(accident.causa)\n",
    "        \n",
    "print(set(types_n))\n",
    "cause_n = [i for i in set(types_n)]\n",
    "cause_ammount_n = [0]*len(cause_n)\n",
    "\n",
    "for acc in types_n:\n",
    "    cause_ammount_n[cause_n.index(acc)] = cause_ammount_n[cause_n.index(acc)] + 1\n",
    "    \n",
    "print(cause_ammount_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14473684210526316, 0.046992481203007516, 0.5620300751879699, 0.022556390977443608, 0.2236842105263158]\n",
      "[0.08289455920075604, 0.006750371270419873, 0.6649115701363575, 0.009990549480221413, 0.23545294991224516]\n"
     ]
    }
   ],
   "source": [
    "#We normalise the data\n",
    "total_y = sum(cause_ammount_y)\n",
    "total_n = sum(cause_ammount_n)\n",
    "\n",
    "for index in range(len(cause_y)):\n",
    "    cause_ammount_n[index] = cause_ammount_n[index]/total_n\n",
    "    cause_ammount_y[index] = cause_ammount_y[index]/total_y\n",
    "\n",
    "print(cause_ammount_y)\n",
    "print(cause_ammount_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are way more \"vuelco\", \"tijera camión\" and \"atropello\" in the ones with roadworks"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
